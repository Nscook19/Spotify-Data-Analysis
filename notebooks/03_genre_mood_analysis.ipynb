{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97d314aa",
   "metadata": {},
   "source": [
    "# Adding Genre Data via Spotipy and Spotify API Access\n",
    "- This will allow me to do more in depth analysis on my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0684bd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "# Load variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "client_id = os.getenv('SPOTIPY_CLIENT_ID')\n",
    "client_secret = os.getenv('SPOTIPY_CLIENT_SECRET')\n",
    "\n",
    "auth_manager = SpotifyClientCredentials(client_id=client_id, client_secret=client_secret)\n",
    "sp = spotipy.Spotify(auth_manager=auth_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8ef9a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m os.listdir(data_path):\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m file.endswith(\u001b[33m'\u001b[39m\u001b[33m.json\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m         dfs.append(\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     13\u001b[39m df = pd.concat(dfs, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Clean up the data\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nscoo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\json\\_json.py:815\u001b[39m, in \u001b[36mread_json\u001b[39m\u001b[34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[39m\n\u001b[32m    813\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n\u001b[32m    814\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m815\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nscoo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\json\\_json.py:1014\u001b[39m, in \u001b[36mJsonReader.read\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1012\u001b[39m         obj = \u001b[38;5;28mself\u001b[39m._get_object_parser(\u001b[38;5;28mself\u001b[39m._combine_lines(data_lines))\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_object_parser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj.convert_dtypes(\n\u001b[32m   1017\u001b[39m         infer_objects=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype_backend=\u001b[38;5;28mself\u001b[39m.dtype_backend\n\u001b[32m   1018\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nscoo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\json\\_json.py:1040\u001b[39m, in \u001b[36mJsonReader._get_object_parser\u001b[39m\u001b[34m(self, json)\u001b[39m\n\u001b[32m   1038\u001b[39m obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1039\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ == \u001b[33m\"\u001b[39m\u001b[33mframe\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1040\u001b[39m     obj = \u001b[43mFrameParser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ == \u001b[33m\"\u001b[39m\u001b[33mseries\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1043\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mbool\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nscoo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\json\\_json.py:1176\u001b[39m, in \u001b[36mParser.parse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1174\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m   1175\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1176\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1179\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nscoo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\json\\_json.py:1391\u001b[39m, in \u001b[36mFrameParser._parse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1388\u001b[39m orient = \u001b[38;5;28mself\u001b[39m.orient\n\u001b[32m   1390\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m orient == \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1391\u001b[39m     \u001b[38;5;28mself\u001b[39m.obj = \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mujson_loads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   1393\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m orient == \u001b[33m\"\u001b[39m\u001b[33msplit\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1395\u001b[39m     decoded = {\n\u001b[32m   1396\u001b[39m         \u001b[38;5;28mstr\u001b[39m(k): v\n\u001b[32m   1397\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m ujson_loads(json, precise_float=\u001b[38;5;28mself\u001b[39m.precise_float).items()\n\u001b[32m   1398\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nscoo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    772\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    773\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    774\u001b[39m     )\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    777\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nscoo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nscoo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         index = \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    116\u001b[39m         index = ensure_index(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Nscoo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[39m, in \u001b[36m_extract_index\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    675\u001b[39m lengths = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[32m    676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAll arrays must be of the same length\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    681\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    682\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Load your actual Spotify data (same as in initial exploration)\n",
    "data_path = '../data/Spotify Extended Streaming History'\n",
    "dfs = []\n",
    "\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith('.json') and file != 'artist_genre_map.json':\n",
    "        dfs.append(pd.read_json(os.path.join(data_path, file)))\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Clean up the data\n",
    "df['ts'] = pd.to_datetime(df['ts'])\n",
    "df['year'] = df['ts'].dt.year\n",
    "df['month'] = df['ts'].dt.month\n",
    "df['hour'] = df['ts'].dt.hour\n",
    "\n",
    "df.rename(columns={'master_metadata_album_artist_name': 'artist', 'master_metadata_track_name': 'track'}, inplace=True)\n",
    "\n",
    "# Get all unique artists from your listening history\n",
    "unique_artists = df['artist'].dropna().unique()\n",
    "print(f\"Found {len(unique_artists)} unique artists in your listening history\")\n",
    "\n",
    "genre_map_path = os.path.join(data_path, 'artist_genre_map.json')\n",
    "\n",
    "if os.path.exists(genre_map_path):\n",
    "    print(\"Loading artist_genre_map from cache...\")\n",
    "    with open(genre_map_path, 'r', encoding='utf-8') as f:\n",
    "        if os.stat(genre_map_path).st_size == 0:  # Check if the file is empty\n",
    "            print(\"The artist_genre_map.json file is empty. Initializing an empty dictionary.\")\n",
    "            artist_genre_map = {}\n",
    "        else:\n",
    "            artist_genre_map = json.load(f)\n",
    "else:\n",
    "    print(\"Generating artist_genre_map from Spotify API...\")\n",
    "    artist_genre_map = {}\n",
    "    processed = 0\n",
    "\n",
    "    for artist in unique_artists:\n",
    "        try:\n",
    "            results = sp.search(q=f'artist:{artist}', type='artist', limit=1)\n",
    "            items = results['artists']['items']\n",
    "            if items:\n",
    "                genres = items[0]['genres']\n",
    "                artist_genre_map[artist] = genres\n",
    "            else:\n",
    "                artist_genre_map[artist] = []\n",
    "\n",
    "            processed += 1\n",
    "            if processed % 50 == 0:\n",
    "                print(f\"Processed {processed}/{len(unique_artists)} artists\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {artist}: {e}\")\n",
    "            artist_genre_map[artist] = []\n",
    "\n",
    "    with open(genre_map_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(artist_genre_map, f, indent=2)\n",
    "    print(\"Saved artist_genre_map to JSON.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f269c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 120,702 plays with unknown genres\n",
      "\n",
      "Total plays: 118,263\n",
      "Unique genres: 378\n",
      "\n",
      "Top 10 genres by play count:\n",
      "genre\n",
      "rap                     41052\n",
      "rage rap                14310\n",
      "melodic rap             13662\n",
      "hip hop                  6361\n",
      "r&b                      2723\n",
      "chicago drill            1980\n",
      "metal                    1800\n",
      "alternative hip hop      1796\n",
      "southern hip hop         1765\n",
      "experimental hip hop     1678\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of artists with their genres:\n",
      "                                             artist              genre\n",
      "0                                     Drowning Pool           nu metal\n",
      "1                                       DevilDriver       groove metal\n",
      "2                                         Disturbed              metal\n",
      "3                                         Metallica              metal\n",
      "4                          Rage Against The Machine          rap metal\n",
      "5                                       Linkin Park           nu metal\n",
      "8                                          Godsmack           nu metal\n",
      "11                                         Slipknot           nu metal\n",
      "13                                 System Of A Down           nu metal\n",
      "18                                 Three Days Grace        post-grunge\n",
      "21                                   Alien Ant Farm           nu metal\n",
      "25                                   Marilyn Manson   industrial metal\n",
      "27                                      Limp Bizkit           nu metal\n",
      "28                                     Machine Head       groove metal\n",
      "108                                           Drake                rap\n",
      "133  The Presidents Of The United States Of America             grunge\n",
      "134                                Smile Empty Soul        post-grunge\n",
      "135                               Breaking Benjamin  alternative metal\n",
      "137                                          Saliva           nu metal\n",
      "163                                           Trapt        post-grunge\n"
     ]
    }
   ],
   "source": [
    "# --- Assign genres and clean ---\n",
    "df['genre'] = df['artist'].map(lambda a: artist_genre_map.get(a, ['Unknown'])[0] if artist_genre_map.get(a) else 'Unknown')\n",
    "\n",
    "# Filter out unknown genres\n",
    "before = len(df)\n",
    "df = df[df['genre'] != 'Unknown']\n",
    "after = len(df)\n",
    "print(f\"Dropped {before - after:,} plays with unknown genres\")\n",
    "\n",
    "# --- Summary stats ---\n",
    "total_plays = len(df)\n",
    "genre_counts = df['genre'].value_counts()\n",
    "\n",
    "print(f\"\\nTotal plays: {total_plays:,}\")\n",
    "print(f\"Unique genres: {df['genre'].nunique()}\")\n",
    "print(f\"\\nTop 10 genres by play count:\\n{genre_counts.head(10)}\")\n",
    "\n",
    "# --- Sample of artists with genres ---\n",
    "print(\"\\nSample of artists with their genres:\")\n",
    "print(df[['artist', 'genre']].drop_duplicates().head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
